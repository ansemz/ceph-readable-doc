

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>CephFS Mirroring &mdash; Ceph Documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/ceph.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/ceph.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />
    <link rel="next" title="CephFS Reclaim Interface" href="../cephfs-reclaim/" />
    <link rel="prev" title="如何配置好 Ceph Kerberos 认证的详细文档" href="../ceph_krb_auth/" /> 
</head>

<body class="wy-body-for-nav">

   
  <header class="top-bar">
    <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../internals/">Ceph 内幕</a></li>
      <li class="breadcrumb-item active">CephFS Mirroring</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/dev/cephfs-mirroring.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
  </header>
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #eee" >
          

          
            <a href="../../" class="icon icon-home"> Ceph
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../start/">Ceph 简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/">安装 Ceph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cephadm/">Cephadm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rados/">Ceph 存储集群</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cephfs/">Ceph 文件系统</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rbd/">Ceph 块设备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../radosgw/">Ceph 对象网关</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mgr/">Ceph 管理器守护进程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mgr/dashboard/">Ceph 仪表盘</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../monitoring/">监控概览</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/">API 文档</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../architecture/">体系结构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/">开发者指南</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../internals/">Ceph 内幕</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../balancer-design/">Ceph 如何均衡（读写、容量）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blkin/">Tracing Ceph With LTTng</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blkin/#tracing-ceph-with-blkin">Tracing Ceph With Blkin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bluestore/">BlueStore Internals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ceph_krb_auth/">如何配置好 Ceph Kerberos 认证的详细文档</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">CephFS Mirroring</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#key-idea">Key Idea</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creating-users">Creating Users</a></li>
<li class="toctree-l3"><a class="reference internal" href="#starting-mirror-daemon">Starting Mirror Daemon</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mirroring-design">Mirroring Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="#snapshot-synchronization-order">Snapshot Synchronization Order</a></li>
<li class="toctree-l3"><a class="reference internal" href="#snapshot-incarnation">Snapshot Incarnation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#interfaces">Interfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mirroring-module-and-interface">Mirroring Module and Interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bootstrap-peers">Bootstrap Peers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mirror-daemon-status">Mirror Daemon Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="#re-adding-peers">Re-adding Peers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#feature-status">Feature Status</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../cephfs-reclaim/">CephFS Reclaim Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cephfs-snapshots/">CephFS 快照</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cephx/">Cephx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cephx_protocol/">Cephx 认证协议详细阐述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../config/">配置管理系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../config-key/">config-key layout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../context/">CephContext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../continuous-integration/">Continuous Integration Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/">资料库结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cpu-profiler/">Oprofile 的安装</a></li>
<li class="toctree-l2"><a class="reference internal" href="../crush-msr/">CRUSH MSR (Multi-step Retry)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cxx/">C++17 and libstdc++ ABI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deduplication/">去重</a></li>
<li class="toctree-l2"><a class="reference internal" href="../delayed-delete/">CephFS delayed deletion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_cluster_deployment/">开发集群的部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dev_cluster_deployment/#id5">在同一机器上部署多套开发集群</a></li>
<li class="toctree-l2"><a class="reference internal" href="../development-workflow/">开发流程</a></li>
<li class="toctree-l2"><a class="reference internal" href="../documenting/">为 Ceph 写作文档</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dpdk/">Ceph messenger DPDKStack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../encoding/">序列化（编码、解码）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../erasure-coded-pool/">纠删码存储池</a></li>
<li class="toctree-l2"><a class="reference internal" href="../file-striping/">File striping</a></li>
<li class="toctree-l2"><a class="reference internal" href="../freebsd/">FreeBSD Implementation details</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generatedocs/">Ceph 文档的构建</a></li>
<li class="toctree-l2"><a class="reference internal" href="../health-reports/">Health Reports</a></li>
<li class="toctree-l2"><a class="reference internal" href="../iana/">IANA 号</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kclient/">Testing changes to the Linux Kernel CephFS driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kclient/#step-one-build-the-kernel">Step One: build the kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kclient/#step-two-create-a-vm">Step Two: create a VM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kclient/#step-three-networking-the-vm">Step Three: Networking the VM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kubernetes/">Hacking on Ceph in Kubernetes with Rook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../libcephfs_proxy/">Design of the libcephfs proxy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../libs/">库体系结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../logging/">集群日志的用法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../logs/">调试日志</a></li>
<li class="toctree-l2"><a class="reference internal" href="../macos/">在 MacOS 上构建</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mempool_accounting/">What is a mempool?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mempool_accounting/#some-common-mempools-that-we-can-track">Some common mempools that we can track</a></li>
<li class="toctree-l2"><a class="reference internal" href="../messenger/">Messenger notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mon-bootstrap/">Monitor bootstrap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mon-elections/">Monitor Elections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mon-on-disk-formats/">ON-DISK FORMAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mon-osdmap-prune/">FULL OSDMAP VERSION PRUNING</a></li>
<li class="toctree-l2"><a class="reference internal" href="../msgr2/">msgr2 协议（ msgr2.0 和 msgr2.1 ）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../network-encoding/">Network Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../network-protocol/">网络协议</a></li>
<li class="toctree-l2"><a class="reference internal" href="../object-store/">对象存储架构概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../osd-class-path/">OSD class path issues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../peering/">互联</a></li>
<li class="toctree-l2"><a class="reference internal" href="../perf/">Using perf</a></li>
<li class="toctree-l2"><a class="reference internal" href="../perf_counters/">性能计数器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../perf_histograms/">Perf histograms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../placement-group/">PG （归置组）说明</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quick_guide/">开发者指南（快速）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rados-client-protocol/">RADOS 客户端协议</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rbd-diff/">RBD 增量备份</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rbd-export/">RBD Export &amp; Import</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rbd-layering/">RBD Layering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release-checklists/">Release checklists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../release-process/">Ceph Release Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../seastore/">SeaStore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sepia/">Sepia 社区测试实验室</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session_authentication/">Session Authentication for the Cephx Protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="../testing/">测试笔记</a></li>
<li class="toctree-l2"><a class="reference internal" href="../versions/">Public OSD Version</a></li>
<li class="toctree-l2"><a class="reference internal" href="../vstart-ganesha/">NFS CephFS-RGW Developer Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../wireshark/">Wireshark Dissector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../zoned-storage/">Zoned Storage Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="../osd_internals/">OSD 开发者文档</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mds_internals/">MDS 开发者文档</a></li>
<li class="toctree-l2"><a class="reference internal" href="../radosgw/">RADOS 网关开发者文档</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ceph-volume/">ceph-volume 开发者文档</a></li>
<li class="toctree-l2"><a class="reference internal" href="../crimson/">Crimson developer documentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../governance/">项目管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../foundation/">Ceph 基金会</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ceph-volume/">ceph-volume</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases/general/">Ceph 版本（总目录）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases/">Ceph 版本（索引）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../security/">Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hardware-monitoring/">硬件监控</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary/">Ceph 术语</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jaegertracing/">Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../translation_cn/">中文版翻译资源</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../">Ceph</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
<div id="dev-warning" class="admonition note">
  <p class="first admonition-title">Notice</p>
  <p class="last">This document is for a development version of Ceph.</p>
</div>
  <div id="docubetter" align="right" style="padding: 5px; font-weight: bold;">
    <a href="https://pad.ceph.com/p/Report_Documentation_Bugs">Report a Documentation Bug</a>
  </div>

  
  <section id="cephfs-mirroring">
<h1>CephFS Mirroring<a class="headerlink" href="#cephfs-mirroring" title="Permalink to this heading"></a></h1>
<p>CephFS supports asynchronous replication of snapshots to a remote CephFS file system via
<cite>cephfs-mirror</cite> tool. Snapshots are synchronized by mirroring snapshot data followed by
creating a snapshot with the same name (for a given directory on the remote file system) as
the snapshot being synchronized.</p>
<section id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this heading"></a></h2>
<p>The primary (local) and secondary (remote) Ceph clusters version should be Pacific or later.</p>
</section>
<section id="key-idea">
<h2>Key Idea<a class="headerlink" href="#key-idea" title="Permalink to this heading"></a></h2>
<p>For a given snapshot pair in a directory, <cite>cephfs-mirror</cite> daemon will rely on readdir diff
to identify changes in a directory tree. The diffs are applied to directory in the remote
file system thereby only synchronizing files that have changed between two snapshots.</p>
<p>This feature is tracked here: <a class="reference external" href="https://tracker.ceph.com/issues/47034">https://tracker.ceph.com/issues/47034</a>.</p>
<p>Currently, snapshot data is synchronized by bulk copying to the remote filesystem.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Synchronizing hardlinks is not supported -- hardlinked files get synchronized
as separate files.</p>
</div>
</section>
<section id="creating-users">
<h2>Creating Users<a class="headerlink" href="#creating-users" title="Permalink to this heading"></a></h2>
<p>Start by creating a user (on the primary/local cluster) for the mirror daemon. This user
requires write capability on the metadata pool to create RADOS objects (index objects)
for watch/notify operation and read capability on the data pool(s).</p>
<blockquote>
<div><p>$ ceph auth get-or-create client.mirror mon ‘profile cephfs-mirror’ mds ‘allow r’ osd ‘allow rw tag cephfs metadata=*, allow r tag cephfs data=*’ mgr ‘allow r’</p>
</div></blockquote>
<p>Create a user for each file system peer (on the secondary/remote cluster). This user needs
to have full capabilities on the MDS (to take snapshots) and the OSDs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs authorize &lt;fs_name&gt; client.mirror_remote / rwps
</pre></div>
</div>
<p>This user should be used (as part of peer specification) when adding a peer.</p>
</section>
<section id="starting-mirror-daemon">
<h2>Starting Mirror Daemon<a class="headerlink" href="#starting-mirror-daemon" title="Permalink to this heading"></a></h2>
<p>Mirror daemon should be spawned using <cite>systemctl(1)</cite> unit files:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ systemctl enable cephfs-mirror@mirror
$ systemctl start cephfs-mirror@mirror
</pre></div>
</div>
<p><cite>cephfs-mirror</cite> daemon can be run in foreground using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cephfs-mirror --id mirror --cluster site-a -f
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>User used here is <cite>mirror</cite> as created in the <cite>Creating Users</cite> section.</p>
</div>
</section>
<section id="mirroring-design">
<h2>Mirroring Design<a class="headerlink" href="#mirroring-design" title="Permalink to this heading"></a></h2>
<p>CephFS supports asynchronous replication of snapshots to a remote CephFS file system
via <cite>cephfs-mirror</cite> tool. For a given directory, snapshots are synchronized by transferring
snapshot data to the remote file system and creating a snapshot with the same name as the
snapshot being synchronized.</p>
</section>
<section id="snapshot-synchronization-order">
<h2>Snapshot Synchronization Order<a class="headerlink" href="#snapshot-synchronization-order" title="Permalink to this heading"></a></h2>
<p>Although the order in which snapshots get chosen for synchronization does not matter,
snapshots are picked based on creation order (using snap-id).</p>
</section>
<section id="snapshot-incarnation">
<h2>Snapshot Incarnation<a class="headerlink" href="#snapshot-incarnation" title="Permalink to this heading"></a></h2>
<p>A snapshot may be deleted and recreated (with the same name) with different contents.
An “old” snapshot could have been synchronized (earlier) and the recreation of the
snapshot could have been done when mirroring was disabled. Using snapshot names to
infer the point-of-continuation would result in the “new” snapshot (incarnation)
never getting picked up for synchronization.</p>
<p>Snapshots on the secondary file system stores the snap-id of the snapshot it was
synchronized from. This metadata is stored in <cite>SnapInfo</cite> structure on the MDS.</p>
</section>
<section id="interfaces">
<h2>Interfaces<a class="headerlink" href="#interfaces" title="Permalink to this heading"></a></h2>
<p><cite>Mirroring</cite> module (manager plugin) provides interfaces for managing directory snapshot
mirroring. Manager interfaces are (mostly) wrappers around monitor commands for managing
file system mirroring and is the recommended control interface.</p>
</section>
<section id="mirroring-module-and-interface">
<h2>Mirroring Module and Interface<a class="headerlink" href="#mirroring-module-and-interface" title="Permalink to this heading"></a></h2>
<p>Mirroring module provides interface for managing directory snapshot mirroring. The module
is implemented as a Ceph Manager plugin. Mirroring module does not manage spawning (and
terminating) the mirror daemons. Right now the preferred way would be to start/stop
mirror daemons via <cite>systemctl(1)</cite>. Going forward, deploying mirror daemons would be
managed by <cite>cephadm</cite> (Tracker: <a class="reference external" href="http://tracker.ceph.com/issues/47261">http://tracker.ceph.com/issues/47261</a>).</p>
<p>The manager module is responsible for assigning directories to mirror daemons for
synchronization. Multiple mirror daemons can be spawned to achieve concurrency in
directory snapshot synchronization. When mirror daemons are spawned (or terminated)
, the mirroring module discovers the modified set of mirror daemons and rebalances
the directory assignment amongst the new set thus providing high-availability.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Multiple mirror daemons is currently untested. Only a single mirror daemon
is recommended.</p>
</div>
<p>Mirroring module is disabled by default. To enable mirroring use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph mgr module enable mirroring
</pre></div>
</div>
<p>Mirroring module provides a family of commands to control mirroring of directory
snapshots. To add or remove directories, mirroring needs to be enabled for a given
file system. To enable mirroring use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror enable &lt;fs_name&gt;
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Mirroring module commands use <cite>fs snapshot mirror</cite> prefix as compared to
the monitor commands which <cite>fs mirror</cite> prefix. Make sure to use module
commands.</p>
</div>
<p>To disable mirroring, use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror disable &lt;fs_name&gt;
</pre></div>
</div>
<p>Once mirroring is enabled, add a peer to which directory snapshots are to be mirrored.
Peers follow <cite>&lt;client&gt;&#64;&lt;cluster&gt;</cite> specification and get assigned a unique-id (UUID)
when added. See <cite>Creating Users</cite> section on how to create Ceph users for mirroring.</p>
<p>To add a peer use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror peer_add &lt;fs_name&gt; &lt;remote_cluster_spec&gt; [&lt;remote_fs_name&gt;] [&lt;remote_mon_host&gt;] [&lt;cephx_key&gt;]
</pre></div>
</div>
<p><cite>&lt;remote_fs_name&gt;</cite> is optional, and default to <cite>&lt;fs_name&gt;</cite> (on the remote cluster).</p>
<p>This requires the remote cluster ceph configuration and user keyring to be available in
the primary cluster. See <cite>Bootstrap Peers</cite> section to avoid this. <cite>peer_add</cite> additionally
supports passing the remote cluster monitor address and the user key. However, bootstrapping
a peer is the recommended way to add a peer.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Only a single peer is supported right now.</p>
</div>
<p>To remove a peer use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror peer_remove &lt;fs_name&gt; &lt;peer_uuid&gt;
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>See <cite>Mirror Daemon Status</cite> section on how to figure out Peer UUID.</p>
</div>
<p>To list file system mirror peers use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror peer_list &lt;fs_name&gt;
</pre></div>
</div>
<p>To configure a directory for mirroring, use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror add &lt;fs_name&gt; &lt;path&gt;
</pre></div>
</div>
<p>To stop a mirroring directory snapshots use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror remove &lt;fs_name&gt; &lt;path&gt;
</pre></div>
</div>
<p>Only absolute directory paths are allowed. Also, paths are normalized by the mirroring
module, therfore, <cite>/a/b/../b</cite> is equivalent to <cite>/a/b</cite>.</p>
<blockquote>
<div><p>$ mkdir -p /d0/d1/d2
$ ceph fs snapshot mirror add cephfs /d0/d1/d2
{}
$ ceph fs snapshot mirror add cephfs /d0/d1/../d1/d2
Error EEXIST: directory /d0/d1/d2 is already tracked</p>
</div></blockquote>
<p>Once a directory is added for mirroring, its subdirectory or ancestor directories are
disallowed to be added for mirorring:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror add cephfs /d0/d1
Error EINVAL: /d0/d1 is a ancestor of tracked path /d0/d1/d2
$ ceph fs snapshot mirror add cephfs /d0/d1/d2/d3
Error EINVAL: /d0/d1/d2/d3 is a subtree of tracked path /d0/d1/d2
</pre></div>
</div>
<p>Commands to check directory mapping (to mirror daemons) and directory distribution are
detailed in <cite>Mirror Daemon Status</cite> section.</p>
</section>
<section id="bootstrap-peers">
<h2>Bootstrap Peers<a class="headerlink" href="#bootstrap-peers" title="Permalink to this heading"></a></h2>
<p>Adding a peer (via <cite>peer_add</cite>) requires the peer cluster configuration and user keyring
to be available in the primary cluster (manager host and hosts running the mirror daemon).
This can be avoided by bootstrapping and importing a peer token. Peer bootstrap involves
creating a bootstrap token on the peer cluster via:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror peer_bootstrap create &lt;fs_name&gt; &lt;client_entity&gt; &lt;site-name&gt;
</pre></div>
</div>
<p>e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror peer_bootstrap create backup_fs client.mirror_remote site-remote
{&quot;token&quot;: &quot;eyJmc2lkIjogIjBkZjE3MjE3LWRmY2QtNDAzMC05MDc5LTM2Nzk4NTVkNDJlZiIsICJmaWxlc3lzdGVtIjogImJhY2t1cF9mcyIsICJ1c2VyIjogImNsaWVudC5taXJyb3JfcGVlcl9ib290c3RyYXAiLCAic2l0ZV9uYW1lIjogInNpdGUtcmVtb3RlIiwgImtleSI6ICJBUUFhcDBCZ0xtRmpOeEFBVnNyZXozai9YYUV0T2UrbUJEZlJDZz09IiwgIm1vbl9ob3N0IjogIlt2MjoxOTIuMTY4LjAuNTo0MDkxOCx2MToxOTIuMTY4LjAuNTo0MDkxOV0ifQ==&quot;}
</pre></div>
</div>
<p><cite>site-name</cite> refers to a user-defined string to identify the remote filesystem. In context
of <cite>peer_add</cite> interface, <cite>site-name</cite> is the passed in <cite>cluster</cite> name from <cite>remote_cluster_spec</cite>.</p>
<p>Import the bootstrap token in the primary cluster via:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror peer_bootstrap import &lt;fs_name&gt; &lt;token&gt;
</pre></div>
</div>
<p>e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror peer_bootstrap import cephfs eyJmc2lkIjogIjBkZjE3MjE3LWRmY2QtNDAzMC05MDc5LTM2Nzk4NTVkNDJlZiIsICJmaWxlc3lzdGVtIjogImJhY2t1cF9mcyIsICJ1c2VyIjogImNsaWVudC5taXJyb3JfcGVlcl9ib290c3RyYXAiLCAic2l0ZV9uYW1lIjogInNpdGUtcmVtb3RlIiwgImtleSI6ICJBUUFhcDBCZ0xtRmpOeEFBVnNyZXozai9YYUV0T2UrbUJEZlJDZz09IiwgIm1vbl9ob3N0IjogIlt2MjoxOTIuMTY4LjAuNTo0MDkxOCx2MToxOTIuMTY4LjAuNTo0MDkxOV0ifQ==
</pre></div>
</div>
</section>
<section id="mirror-daemon-status">
<h2>Mirror Daemon Status<a class="headerlink" href="#mirror-daemon-status" title="Permalink to this heading"></a></h2>
<p>Mirror daemons get asynchronously notified about changes in file system mirroring status
and/or peer updates.</p>
<p>CephFS mirroring module provides <cite>mirror daemon status</cite> interface to check mirror daemon
status:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror daemon status
</pre></div>
</div>
<p>E.g:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror daemon status | jq
[
  {
    &quot;daemon_id&quot;: 284167,
    &quot;filesystems&quot;: [
      {
        &quot;filesystem_id&quot;: 1,
        &quot;name&quot;: &quot;a&quot;,
        &quot;directory_count&quot;: 1,
        &quot;peers&quot;: [
          {
            &quot;uuid&quot;: &quot;02117353-8cd1-44db-976b-eb20609aa160&quot;,
            &quot;remote&quot;: {
              &quot;client_name&quot;: &quot;client.mirror_remote&quot;,
              &quot;cluster_name&quot;: &quot;ceph&quot;,
              &quot;fs_name&quot;: &quot;backup_fs&quot;
            },
            &quot;stats&quot;: {
              &quot;failure_count&quot;: 1,
              &quot;recovery_count&quot;: 0
            }
          }
        ]
      }
    ]
  }
]
</pre></div>
</div>
<p>An entry per mirror daemon instance is displayed along with information such as configured
peers and basic stats. For more detailed stats, use the admin socket interface as detailed
below.</p>
<p>CephFS mirror daemons provide admin socket commands for querying mirror status. To check
available commands for mirror status use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph --admin-daemon /path/to/mirror/daemon/admin/socket help
{
    ....
    ....
    &quot;fs mirror status cephfs@360&quot;: &quot;get filesystem mirror status&quot;,
    ....
    ....
}
</pre></div>
</div>
<p>Commands with <cite>fs mirror status</cite> prefix provide mirror status for mirror enabled
file systems. Note that <cite>cephfs&#64;360</cite> is of format <cite>filesystem-name&#64;filesystem-id</cite>.
This format is required since mirror daemons get asynchronously notified regarding
file system mirror status (A file system can be deleted and recreated with the same
name).</p>
<p>Right now, the command provides minimal information regarding mirror status:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph --admin-daemon /var/run/ceph/cephfs-mirror.asok fs mirror status cephfs@360
{
  &quot;rados_inst&quot;: &quot;192.168.0.5:0/1476644347&quot;,
  &quot;peers&quot;: {
      &quot;a2dc7784-e7a1-4723-b103-03ee8d8768f8&quot;: {
          &quot;remote&quot;: {
              &quot;client_name&quot;: &quot;client.mirror_remote&quot;,
              &quot;cluster_name&quot;: &quot;site-a&quot;,
              &quot;fs_name&quot;: &quot;backup_fs&quot;
          }
      }
  },
  &quot;snap_dirs&quot;: {
      &quot;dir_count&quot;: 1
  }
}
</pre></div>
</div>
<p><cite>Peers</cite> section in the command output above shows the peer information such as unique
peer-id (UUID) and specification. The peer-id is required to remove an existing peer
as mentioned in the <cite>Mirror Module and Interface</cite> section.</p>
<p>Command with <cite>fs mirror peer status</cite> prefix provide peer synchronization status. This
command is of format <cite>filesystem-name&#64;filesystem-id peer-uuid</cite>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph --admin-daemon /var/run/ceph/cephfs-mirror.asok fs mirror peer status cephfs@360 a2dc7784-e7a1-4723-b103-03ee8d8768f8
{
  &quot;/d0&quot;: {
      &quot;state&quot;: &quot;idle&quot;,
      &quot;last_synced_snap&quot;: {
          &quot;id&quot;: 120,
          &quot;name&quot;: &quot;snap1&quot;,
          &quot;sync_duration&quot;: 0.079997898999999997,
          &quot;sync_time_stamp&quot;: &quot;274900.558797s&quot;
      },
      &quot;snaps_synced&quot;: 2,
      &quot;snaps_deleted&quot;: 0,
      &quot;snaps_renamed&quot;: 0
  }
}
</pre></div>
</div>
<p>Synchronization stats such as <cite>snaps_synced</cite>, <cite>snaps_deleted</cite> and <cite>snaps_renamed</cite> are reset
on daemon restart and/or when a directory is reassigned to another mirror daemon (when
multiple mirror daemons are deployed).</p>
<p>A directory can be in one of the following states:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- `idle`: The directory is currently not being synchronized
- `syncing`: The directory is currently being synchronized
- `failed`: The directory has hit upper limit of consecutive failures
</pre></div>
</div>
<p>When a directory hits a configured number of consecutive synchronization failures, the
mirror daemon marks it as <cite>failed</cite>. Synchronization for these directories are retried.
By default, the number of consecutive failures before a directory is marked as failed
is controlled by <cite>cephfs_mirror_max_consecutive_failures_per_directory</cite> configuration
option (default: 10) and the retry interval for failed directories is controlled via
<cite>cephfs_mirror_retry_failed_directories_interval</cite> configuration option (default: 60s).</p>
<p>E.g., adding a regular file for synchronization would result in failed status:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror add cephfs /f0
$ ceph --admin-daemon /var/run/ceph/cephfs-mirror.asok fs mirror peer status cephfs@360 a2dc7784-e7a1-4723-b103-03ee8d8768f8
{
  &quot;/d0&quot;: {
      &quot;state&quot;: &quot;idle&quot;,
      &quot;last_synced_snap&quot;: {
          &quot;id&quot;: 120,
          &quot;name&quot;: &quot;snap1&quot;,
          &quot;sync_duration&quot;: 0.079997898999999997,
          &quot;sync_time_stamp&quot;: &quot;274900.558797s&quot;
      },
      &quot;snaps_synced&quot;: 2,
      &quot;snaps_deleted&quot;: 0,
      &quot;snaps_renamed&quot;: 0
  },
  &quot;/f0&quot;: {
      &quot;state&quot;: &quot;failed&quot;,
      &quot;snaps_synced&quot;: 0,
      &quot;snaps_deleted&quot;: 0,
      &quot;snaps_renamed&quot;: 0
  }
}
</pre></div>
</div>
<p>This allows a user to add a non-existent directory for synchronization. The mirror daemon
would mark the directory as failed and retry (less frequently). When the directory comes
to existence, the mirror daemons would unmark the failed state upon successfull snapshot
synchronization.</p>
<p>When mirroring is disabled, the respective <cite>fs mirror status</cite> command for the file system
will not show up in command help.</p>
<p>Mirroring module provides a couple of commands to display directory mapping and distribution
information. To check which mirror daemon a directory has been mapped to use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror dirmap cephfs /d0/d1/d2
{
  &quot;instance_id&quot;: &quot;404148&quot;,
  &quot;last_shuffled&quot;: 1601284516.10986,
  &quot;state&quot;: &quot;mapped&quot;
}
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>instance_id</cite> is the RAODS instance-id associated with a mirror daemon.</p>
</div>
<p>Other information such as <cite>state</cite> and <cite>last_shuffled</cite> are interesting when running
multiple mirror daemons.</p>
<p>When no mirror daemons are running the above command shows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ceph fs snapshot mirror dirmap cephfs /d0/d1/d2
{
  &quot;reason&quot;: &quot;no mirror daemons running&quot;,
  &quot;state&quot;: &quot;stalled&quot;
}
</pre></div>
</div>
<p>Signifying that no mirror daemons are running and mirroring is stalled.</p>
</section>
<section id="re-adding-peers">
<h2>Re-adding Peers<a class="headerlink" href="#re-adding-peers" title="Permalink to this heading"></a></h2>
<p>When re-adding (reassigning) a peer to a file system in another cluster, ensure that
all mirror daemons have stopped synchronization to the peer. This can be checked
via <cite>fs mirror status</cite> admin socket command (the <cite>Peer UUID</cite> should not show up
in the command output). Also, it is recommended to purge synchronized directories
from the peer  before re-adding it to another file system (especially those directories
which might exist in the new primary file system). This is not required if re-adding
a peer to the same primary file system it was earlier synchronized from.</p>
</section>
<section id="feature-status">
<h2>Feature Status<a class="headerlink" href="#feature-status" title="Permalink to this heading"></a></h2>
<p><cite>cephfs-mirror</cite> daemon is built by default (follows <cite>WITH_CEPHFS</cite> CMake rule).</p>
</section>
</section>



<div id="support-the-ceph-foundation" class="admonition note">
  <p class="first admonition-title">Brought to you by the Ceph Foundation</p>
  <p class="last">The Ceph Documentation is a community resource funded and hosted by the non-profit <a href="https://ceph.io/en/foundation/">Ceph Foundation</a>. If you would like to support this and our other efforts, please consider <a href="https://ceph.io/en/foundation/join/">joining now</a>.</p>
</div>


           </div>
           
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../ceph_krb_auth/" class="btn btn-neutral float-left" title="如何配置好 Ceph Kerberos 认证的详细文档" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../cephfs-reclaim/" class="btn btn-neutral float-right" title="CephFS Reclaim Interface" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016, Ceph authors and contributors. Licensed under Creative Commons Attribution Share Alike 3.0 (CC-BY-SA-3.0).</p>
  </div>

   

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>