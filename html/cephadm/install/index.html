
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>部署个全新的 Ceph 集群 &#8212; Ceph Documentation</title>
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/js/ceph.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />
    <link rel="next" title="现有集群切换到 cephadm" href="../adoption/" />
    <link rel="prev" title="稳定性" href="../stability/" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex/" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex/" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../adoption/" title="现有集群切换到 cephadm"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../stability/" title="稳定性"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../">Ceph Documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../" accesskey="U">Cephadm</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            

<div id="dev-warning" class="admonition note" style="display:none;">
  <p class="first admonition-title">Notice</p>
  <p class="last">This document is for a development version of Ceph.</p>
</div>

<div id="eol-warning" class="admonition warning" style="display:none;">
  <p class="first admonition-title">Warning</p>
  <p class="last">This document is for an unsupported version of Ceph.</p>
</div>
  <div id="docubetter" align="right" style="display:none; padding: 15px; font-weight: bold;">
    <a id="edit-on-github" href="https://github.com/ceph/ceph/edit/master/doc/cephadm/install.rst" rel="nofollow">Edit on GitHub</a> | <a href="https://pad.ceph.com/p/Report_Documentation_Bugs">Report a Documentation Bug</a>
  </div>

  
  <div class="section" id="ceph">
<h1>部署个全新的 Ceph 集群<a class="headerlink" href="#ceph" title="Permalink to this headline">¶</a></h1>
<p>Cephadm creates a new Ceph cluster by “bootstrapping” on a single
host, expanding the cluster to encompass any additional hosts, and
then deploying the needed services.</p>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Systemd</p></li>
<li><p>Podman or Docker for running containers</p></li>
<li><p>Time synchronization (such as chrony or NTP)</p></li>
<li><p>LVM2 for provisioning storage devices</p></li>
</ul>
<p>Any modern Linux distribution should be sufficient.  Dependencies
are installed automatically by the bootstrap process below.</p>
</div>
<div class="section" id="install-cephadm">
<span id="get-cephadm"></span><h2>Install cephadm<a class="headerlink" href="#install-cephadm" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">cephadm</span></code> command can (1) bootstrap a new cluster, (2)
launch a containerized shell with a working Ceph CLI, and (3) aid in
debugging containerized Ceph daemons.</p>
<p>There are a few ways to install cephadm:</p>
<ul>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">curl</span></code> to fetch the most recent version of the
standalone script:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> curl --silent --remote-name --location https://github.com/ceph/ceph/raw/octopus/src/cephadm/cephadm
<span class="gp">#</span> chmod +x cephadm
</pre></div>
</div>
<p>This script can be run directly from the current directory with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ./cephadm &lt;arguments...&gt;
</pre></div>
</div>
</li>
<li><p>Although the standalone script is sufficient to get a cluster started, it is
convenient to have the <code class="docutils literal notranslate"><span class="pre">cephadm</span></code> command installed on the host.  To install
these packages for the current Octopus release:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ./cephadm add-repo --release octopus
<span class="gp">#</span> ./cephadm install
</pre></div>
</div>
<p>Confirm that <code class="docutils literal notranslate"><span class="pre">cephadm</span></code> is now in your PATH with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> which cephadm
</pre></div>
</div>
</li>
<li><p>Some commercial Linux distributions (e.g., RHEL, SLE) may already
include up-to-date Ceph packages.  In that case, you can install
cephadm directly.  For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> dnf install -y cephadm     <span class="c1"># or</span>
<span class="gp">#</span> zypper install -y cephadm
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="bootstrap-a-new-cluster">
<h2>Bootstrap a new cluster<a class="headerlink" href="#bootstrap-a-new-cluster" title="Permalink to this headline">¶</a></h2>
<p>You need to know which <em>IP address</em> to use for the cluster’s first
monitor daemon.  This is normally just the IP for the first host.  If there
are multiple networks and interfaces, be sure to choose one that will
be accessible by any host accessing the Ceph cluster.</p>
<p>To bootstrap the cluster:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> mkdir -p /etc/ceph
<span class="gp">#</span> cephadm bootstrap --mon-ip *&lt;mon-ip&gt;*
</pre></div>
</div>
<p>This command will:</p>
<ul class="simple">
<li><p>Create a monitor and manager daemon for the new cluster on the local
host.</p></li>
<li><p>Generate a new SSH key for the Ceph cluster and adds it to the root
user’s <code class="docutils literal notranslate"><span class="pre">/root/.ssh/authorized_keys</span></code> file.</p></li>
<li><p>Write a minimal configuration file needed to communicate with the
new cluster to <code class="docutils literal notranslate"><span class="pre">/etc/ceph/ceph.conf</span></code>.</p></li>
<li><p>Write a copy of the <code class="docutils literal notranslate"><span class="pre">client.admin</span></code> administrative (privileged!)
secret key to <code class="docutils literal notranslate"><span class="pre">/etc/ceph/ceph.client.admin.keyring</span></code>.</p></li>
<li><p>Write a copy of the public key to
<code class="docutils literal notranslate"><span class="pre">/etc/ceph/ceph.pub</span></code>.</p></li>
</ul>
<p>The default bootstrap behavior will work for the vast majority of
users.  See below for a few options that may be useful for some users,
or run <code class="docutils literal notranslate"><span class="pre">cephadm</span> <span class="pre">bootstrap</span> <span class="pre">-h</span></code> to see all available options:</p>
<ul>
<li><p>Bootstrap writes the files needed to access the new cluster to
<code class="docutils literal notranslate"><span class="pre">/etc/ceph</span></code> for convenience, so that any Ceph packages installed
on the host itself (e.g., to access the command line interface) can
easily find them.</p>
<p>Daemon containers deployed with cephadm, however, do not need
<code class="docutils literal notranslate"><span class="pre">/etc/ceph</span></code> at all.  Use the <code class="docutils literal notranslate"><span class="pre">--output-dir</span> <span class="pre">*&lt;directory&gt;*</span></code> option
to put them in a different directory (like <code class="docutils literal notranslate"><span class="pre">.</span></code>), avoiding any
potential conflicts with existing Ceph configuration (cephadm or
otherwise) on the same host.</p>
</li>
<li><p>You can pass any initial Ceph configuration options to the new
cluster by putting them in a standard ini-style configuration file
and using the <code class="docutils literal notranslate"><span class="pre">--config</span> <span class="pre">*&lt;config-file&gt;*</span></code> option.</p></li>
<li><p>You can choose the ssh user cephadm will use to connect to hosts by
using the <code class="docutils literal notranslate"><span class="pre">--ssh-user</span> <span class="pre">*&lt;user&gt;*</span></code> option. The ssh key will be added
to <code class="docutils literal notranslate"><span class="pre">/home/*&lt;user&gt;*/.ssh/authorized_keys</span></code>. This user will require
passwordless sudo access.</p></li>
</ul>
</div>
<div class="section" id="enable-ceph-cli">
<h2>Enable Ceph CLI<a class="headerlink" href="#enable-ceph-cli" title="Permalink to this headline">¶</a></h2>
<p>Cephadm does not require any Ceph packages to be installed on the
host.  However, we recommend enabling easy access to the <code class="docutils literal notranslate"><span class="pre">ceph</span></code>
command.  There are several ways to do this:</p>
<ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">cephadm</span> <span class="pre">shell</span></code> command launches a bash shell in a container
with all of the Ceph packages installed. By default, if
configuration and keyring files are found in <code class="docutils literal notranslate"><span class="pre">/etc/ceph</span></code> on the
host, they are passed into the container environment so that the
shell is fully functional. Note that when executed on a MON host,
<code class="docutils literal notranslate"><span class="pre">cephadm</span> <span class="pre">shell</span></code> will infer the <code class="docutils literal notranslate"><span class="pre">config</span></code> from the MON container
instead of using the default configuration. If <code class="docutils literal notranslate"><span class="pre">--mount</span> <span class="pre">&lt;path&gt;</span></code>
is given, then the host <code class="docutils literal notranslate"><span class="pre">&lt;path&gt;</span></code> (file or directory) will appear
under <code class="docutils literal notranslate"><span class="pre">/mnt</span></code> inside the container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> cephadm shell
</pre></div>
</div>
</li>
<li><p>It may be helpful to create an alias:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> <span class="nb">alias</span> <span class="nv">ceph</span><span class="o">=</span><span class="s1">&#39;cephadm shell -- ceph&#39;</span>
</pre></div>
</div>
</li>
<li><p>You can install the <code class="docutils literal notranslate"><span class="pre">ceph-common</span></code> package, which contains all of the
ceph commands, including <code class="docutils literal notranslate"><span class="pre">ceph</span></code>, <code class="docutils literal notranslate"><span class="pre">rbd</span></code>, <code class="docutils literal notranslate"><span class="pre">mount.ceph</span></code> (for mounting
CephFS file systems), etc.:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> cephadm add-repo --release octopus
<span class="gp">#</span> cephadm install ceph-common
</pre></div>
</div>
</li>
</ul>
<p>Confirm that the <code class="docutils literal notranslate"><span class="pre">ceph</span></code> command is accessible with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph -v
</pre></div>
</div>
<p>Confirm that the <code class="docutils literal notranslate"><span class="pre">ceph</span></code> command can connect to the cluster and also
its status with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph status
</pre></div>
</div>
</div>
<div class="section" id="add-hosts-to-the-cluster">
<h2>Add hosts to the cluster<a class="headerlink" href="#add-hosts-to-the-cluster" title="Permalink to this headline">¶</a></h2>
<p>To add each new host to the cluster, perform two steps:</p>
<ol class="arabic">
<li><p>Install the cluster’s public SSH key in the new host’s root user’s
<code class="docutils literal notranslate"><span class="pre">authorized_keys</span></code> file:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ssh-copy-id -f -i /etc/ceph/ceph.pub root@*&lt;new-host&gt;*
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ssh-copy-id -f -i /etc/ceph/ceph.pub root@host2
<span class="gp">#</span> ssh-copy-id -f -i /etc/ceph/ceph.pub root@host3
</pre></div>
</div>
</li>
<li><p>Tell Ceph that the new node is part of the cluster:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch host add *newhost*
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch host add host2
<span class="gp">#</span> ceph orch host add host3
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="deploy-additional-monitors-optional">
<span id="deploy-additional-monitors"></span><h2>Deploy additional monitors (optional)<a class="headerlink" href="#deploy-additional-monitors-optional" title="Permalink to this headline">¶</a></h2>
<p>A typical Ceph cluster has three or five monitor daemons spread
across different hosts.  We recommend deploying five
monitors if there are five or more nodes in your cluster.</p>
<p>When Ceph knows what IP subnet the monitors should use it can automatically
deploy and scale monitors as the cluster grows (or contracts).  By default,
Ceph assumes that other monitors should use the same subnet as the first
monitor’s IP.</p>
<p>If your Ceph monitors (or the entire cluster) live on a single subnet,
then by default cephadm automatically adds up to 5 monitors as you add new
hosts to the cluster. No further steps are necessary.</p>
<ul>
<li><p>If there is a specific IP subnet that should be used by monitors, you
can configure that in <a class="reference external" href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation">CIDR</a> format (e.g., <code class="docutils literal notranslate"><span class="pre">10.1.2.0/24</span></code>) with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph config <span class="nb">set</span> mon public_network *&lt;mon-cidr-network&gt;*
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph config <span class="nb">set</span> mon public_network <span class="m">10</span>.1.2.0/24
</pre></div>
</div>
<p>Cephadm only deploys new monitor daemons on hosts that have IPs
configured in the configured subnet.</p>
</li>
<li><p>If you want to adjust the default of 5 monitors:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply mon *&lt;number-of-monitors&gt;*
</pre></div>
</div>
</li>
<li><p>To deploy monitors on a specific set of hosts:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply mon *&lt;host1,host2,host3,...&gt;*
</pre></div>
</div>
<p>Be sure to include the first (bootstrap) host in this list.</p>
</li>
<li><p>You can control which hosts the monitors run on by making use of
host labels.  To set the <code class="docutils literal notranslate"><span class="pre">mon</span></code> label to the appropriate
hosts:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch host label add *&lt;hostname&gt;* mon
</pre></div>
</div>
<p>To view the current hosts and labels:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch host ls
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch host label add host1 mon
<span class="gp">#</span> ceph orch host label add host2 mon
<span class="gp">#</span> ceph orch host label add host3 mon
<span class="gp">#</span> ceph orch host ls
<span class="go">HOST   ADDR   LABELS  STATUS</span>
<span class="go">host1         mon</span>
<span class="go">host2         mon</span>
<span class="go">host3         mon</span>
<span class="go">host4</span>
<span class="go">host5</span>
</pre></div>
</div>
<p>Tell cephadm to deploy monitors based on the label:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply mon label:mon
</pre></div>
</div>
</li>
<li><p>You can explicitly specify the IP address or CIDR network for each monitor
and control where it is placed.  To disable automated monitor deployment:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply mon --unmanaged
</pre></div>
</div>
<p>To deploy each additional monitor:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch daemon add mon *&lt;host1:ip-or-network1&gt; <span class="o">[</span>&lt;host1:ip-or-network-2&gt;...<span class="o">]</span>*
</pre></div>
</div>
<p>For example, to deploy a second monitor on <code class="docutils literal notranslate"><span class="pre">newhost1</span></code> using an IP
address <code class="docutils literal notranslate"><span class="pre">10.1.2.123</span></code> and a third monitor on <code class="docutils literal notranslate"><span class="pre">newhost2</span></code> in
network <code class="docutils literal notranslate"><span class="pre">10.1.2.0/24</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply mon --unmanaged
<span class="gp">#</span> ceph orch daemon add mon newhost1:10.1.2.123
<span class="gp">#</span> ceph orch daemon add mon newhost2:10.1.2.0/24
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="deploy-osds">
<h2>Deploy OSDs<a class="headerlink" href="#deploy-osds" title="Permalink to this headline">¶</a></h2>
<p>An inventory of storage devices on all cluster hosts can be displayed with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch device ls
</pre></div>
</div>
<p>A storage device is considered <em>available</em> if all of the following
conditions are met:</p>
<ul class="simple">
<li><p>The device must have no partitions.</p></li>
<li><p>The device must not have any LVM state.</p></li>
<li><p>The device must not be mounted.</p></li>
<li><p>The device must not contain a file system.</p></li>
<li><p>The device must not contain a Ceph BlueStore OSD.</p></li>
<li><p>The device must be larger than 5 GB.</p></li>
</ul>
<p>Ceph refuses to provision an OSD on a device that is not available.</p>
<p>There are a few ways to create new OSDs:</p>
<ul>
<li><p>Tell Ceph to consume any available and unused storage device:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply osd --all-available-devices
</pre></div>
</div>
</li>
<li><p>Create an OSD from a specific device on a specific host:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch daemon add osd *&lt;host&gt;*:*&lt;device-path&gt;*
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch daemon add osd host1:/dev/sdb
</pre></div>
</div>
</li>
<li><p>Use <a class="reference internal" href="../drivegroups/#drivegroups"><span class="std std-ref">OSD Service Specification</span></a> to describe device(s) to consume
based on their properties, such device type (SSD or HDD), device
model names, size, or the hosts on which the devices exist:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply osd -i spec.yml
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="deploy-mdss">
<h2>Deploy MDSs<a class="headerlink" href="#deploy-mdss" title="Permalink to this headline">¶</a></h2>
<p>One or more MDS daemons is required to use the CephFS file system.
These are created automatically if the newer <code class="docutils literal notranslate"><span class="pre">ceph</span> <span class="pre">fs</span> <span class="pre">volume</span></code>
interface is used to create a new file system.  For more information,
see <a class="reference internal" href="../../cephfs/fs-volumes/#fs-volumes-and-subvolumes"><span class="std std-ref">FS volumes and subvolumes</span></a>.</p>
<p>To deploy metadata servers:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply mds *&lt;fs-name&gt;* --placement<span class="o">=</span><span class="s2">&quot;*&lt;num-daemons&gt;* [*&lt;host1&gt;* ...]&quot;</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="../../mgr/orchestrator/#orchestrator-cli-placement-spec"><span class="std std-ref">Placement Specification</span></a> for details of the placement specification.</p>
</div>
<div class="section" id="deploy-rgws">
<h2>Deploy RGWs<a class="headerlink" href="#deploy-rgws" title="Permalink to this headline">¶</a></h2>
<p>Cephadm deploys radosgw as a collection of daemons that manage a
particular <em>realm</em> and <em>zone</em>.  (For more information about realms and
zones, see <a class="reference internal" href="../../radosgw/multisite/#multisite"><span class="std std-ref">多站</span></a>.)</p>
<p>Note that with cephadm, radosgw daemons are configured via the monitor
configuration database instead of via a <cite>ceph.conf</cite> or the command line.  If
that configuration isn’t already in place (usually in the
<code class="docutils literal notranslate"><span class="pre">client.rgw.&lt;realmname&gt;.&lt;zonename&gt;</span></code> section), then the radosgw
daemons will start up with default settings (e.g., binding to port
80).</p>
<p>If a realm has not been created yet, first create a realm:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> radosgw-admin realm create --rgw-realm<span class="o">=</span>&lt;realm-name&gt; --default
</pre></div>
</div>
<p>Next create a new zonegroup:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> radosgw-admin zonegroup create --rgw-zonegroup<span class="o">=</span>&lt;zonegroup-name&gt;  --master --default
</pre></div>
</div>
<p>Next create a zone:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> radosgw-admin zone create --rgw-zonegroup<span class="o">=</span>&lt;zonegroup-name&gt; --rgw-zone<span class="o">=</span>&lt;zone-name&gt; --master --default
</pre></div>
</div>
<p>To deploy a set of radosgw daemons for a particular realm and zone:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply rgw *&lt;realm-name&gt;* *&lt;zone-name&gt;* --placement<span class="o">=</span><span class="s2">&quot;*&lt;num-daemons&gt;* [*&lt;host1&gt;* ...]&quot;</span>
</pre></div>
</div>
<p>For example, to deploy 2 rgw daemons serving the <em>myorg</em> realm and the <em>us-east-1</em>
zone on <em>myhost1</em> and <em>myhost2</em>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> radosgw-admin realm create --rgw-realm<span class="o">=</span>myorg --default
<span class="gp">#</span> radosgw-admin zonegroup create --rgw-zonegroup<span class="o">=</span>default --master --default
<span class="gp">#</span> radosgw-admin zone create --rgw-zonegroup<span class="o">=</span>default --rgw-zone<span class="o">=</span>us-east-1 --master --default
<span class="gp">#</span> ceph orch apply rgw myorg us-east-1 --placement<span class="o">=</span><span class="s2">&quot;2 myhost1 myhost2&quot;</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="../../mgr/orchestrator/#orchestrator-cli-placement-spec"><span class="std std-ref">Placement Specification</span></a> for details of the placement specification.</p>
</div>
<div class="section" id="deploying-nfs-ganesha">
<h2>Deploying NFS ganesha<a class="headerlink" href="#deploying-nfs-ganesha" title="Permalink to this headline">¶</a></h2>
<p>Cephadm deploys NFS Ganesha using a pre-defined RADOS <em>pool</em>
and optional <em>namespace</em></p>
<p>To deploy a NFS Ganesha gateway,:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply nfs *&lt;svc_id&gt;* *&lt;pool&gt;* *&lt;namespace&gt;* --placement<span class="o">=</span><span class="s2">&quot;*&lt;num-daemons&gt;* [*&lt;host1&gt;* ...]&quot;</span>
</pre></div>
</div>
<p>For example, to deploy NFS with a service id of <em>foo</em>, that will use the
RADOS pool <em>nfs-ganesha</em> and namespace <em>nfs-ns</em>,:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> ceph orch apply nfs foo nfs-ganesha nfs-ns
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Create the <em>nfs-ganesha</em> pool first if it doesn’t exist.</p>
</div>
<p>See <a class="reference internal" href="../../mgr/orchestrator/#orchestrator-cli-placement-spec"><span class="std std-ref">Placement Specification</span></a> for details of the placement specification.</p>
</div>
<div class="section" id="deploying-custom-containers">
<h2>Deploying custom containers<a class="headerlink" href="#deploying-custom-containers" title="Permalink to this headline">¶</a></h2>
<p>It is also possible to choose different containers than the default containers to deploy Ceph. See <a class="reference internal" href="../../install/containers/#containers"><span class="std std-ref">Ceph 容器映像</span></a> for information about your options in this regard.</p>
</div>
</div>



          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../">
              <img class="logo" src="../../_static/logo.png" alt="Logo"/>
            </a></p>
<h3><a href="../../">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../start/intro/">Ceph 简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/">安装 Ceph</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../">Cephadm</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../stability/">稳定性</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">部署个全新的 Ceph 集群</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-cephadm">Install cephadm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bootstrap-a-new-cluster">Bootstrap a new cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="#enable-ceph-cli">Enable Ceph CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#add-hosts-to-the-cluster">Add hosts to the cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploy-additional-monitors-optional">Deploy additional monitors (optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploy-osds">Deploy OSDs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploy-mdss">Deploy MDSs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploy-rgws">Deploy RGWs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploying-nfs-ganesha">Deploying NFS ganesha</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploying-custom-containers">Deploying custom containers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../adoption/">现有集群切换到 cephadm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../operations/">Cephadm operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mgr/orchestrator/">Cephadm CLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../drivegroups/">DriveGroups</a></li>
<li class="toctree-l2"><a class="reference internal" href="../troubleshooting/">故障排除</a></li>
<li class="toctree-l2"><a class="reference internal" href="../concepts/">Cephadm 概念</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../rados/">Ceph 存储集群</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cephfs/">Ceph 文件系统</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rbd/">Ceph 块设备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../radosgw/">Ceph 对象网关</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mgr/">Ceph 管理器守护进程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mgr/dashboard/">Ceph 仪表盘</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/">API 文档</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../architecture/">体系结构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/developer_guide/">开发者指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/internals/">Ceph 内幕</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../governance/">项目管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../foundation/">Ceph 基金会</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ceph-volume/">ceph-volume</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases/general/">Ceph 版本（总目录）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases/">Ceph 版本（索引）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary/">Ceph 术语</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../translation_cn/">中文版翻译资源</a></li>
</ul>


<!-- ugly kludge to make genindex look like it's part of the toc -->
<ul style="margin-top: -10px"><li class="toctree-l1"><a class="reference internal" href="../../genindex/">Index</a></li></ul>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search/" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex/" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex/" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../adoption/" title="现有集群切换到 cephadm"
             >next</a> |</li>
        <li class="right" >
          <a href="../stability/" title="稳定性"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../">Ceph Documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../" >Cephadm</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, Ceph authors and contributors. Licensed under Creative Commons Attribution Share Alike 3.0 (CC-BY-SA-3.0).
    </div>
  </body>
</html>